{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime as datetime\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train_reshape = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test_reshape = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "x_train_reshape = x_train_reshape.astype('float32')\n",
    "x_test_reshape = x_test_reshape.astype('float32')\n",
    "\n",
    "x_train_reshape /= 255\n",
    "x_test_reshape /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train_reshape.shape[0], 'train samples')\n",
    "print(x_test_reshape.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test =to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,\n",
    "                 kernel_initializer='he_normal',))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#tensorboard_callback = TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(x_train_reshape, y_train,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test_reshape, y_test),\n",
    "          #callbacks=[tensorboard_callback]\n",
    "                  )\n",
    "\n",
    "# 8 minutes on GPU P1000\n",
    "# 2 minutes on 2080TX\n",
    "\n",
    "#val_accuracy: 0.9877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_reshape, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer with he_normal:\n",
    "#Test loss: 0.03299637805730106\n",
    "#Test accuracy: 0.9916\n",
    "    \n",
    "# Adadelta with normal optimizer\n",
    "#Test loss: 0.3832157447218895\n",
    "#Test accuracy: 0.8958\n",
    "\n",
    "# Added model.add(Conv2D(128, (3, 3), activation='relu')) and remove dropout\n",
    "#Test loss: 0.04446429884471263\n",
    "#Test accuracy: 0.9915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Visualize Layers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualizing Filters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for layer in model.layers:\n",
    "    if 'conv' not in layer.name:\n",
    "        continue\n",
    "    filters, biases = layer.get_weights()\n",
    "    print(layer.name, filters.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve weights from the second hidden layer\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first few filters\n",
    "n_filters, ix = 4, 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(1):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = plt.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        print(f[:, :, j])\n",
    "        plt.imshow(f[:, :, j], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Visualizing Features Maps </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Extract an image and visualize its value\n",
    "\n",
    "sample_mnsit = x_train[2]\n",
    "plt.imshow(sample_mnsit, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fresh copy of image\n",
    "sample_mnsit = x_train[2]\n",
    "\n",
    "# Reshape to fit classifier\n",
    "sample_mnsit = sample_mnsit.reshape(1, img_rows, img_cols, 1)\n",
    "\n",
    "#Convert to flaot32\n",
    "sample_mnsit = sample_mnsit.astype('float32')\n",
    "\n",
    "# Normalizr features\n",
    "sample_mnsit /= 255\n",
    "\n",
    "# Input layer number you want to extract the feature maps from\n",
    "layer_no = 0\n",
    "\n",
    "# Get the filters from the first layer\n",
    "modified_model = Model(inputs=model.inputs, outputs=model.layers[layer_no].output)\n",
    "\n",
    "# Apply filters to image to get activation function\n",
    "feature_maps  = modified_model.predict(sample_mnsit)\n",
    "\n",
    "# Plot graph of each feature map\n",
    "nrows = int(feature_maps.shape[-1] / 2)\n",
    "ncols = 2\n",
    "fig, axs = plt.subplots(nrows,ncols, \n",
    "                        figsize=(20, 20), \n",
    "                        facecolor='w', \n",
    "                        edgecolor='k',\n",
    "                       )\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "\n",
    "for i in range(feature_maps.shape[-1]):\n",
    "\n",
    "    axs[i].imshow(feature_maps[0, :, :, i], cmap='gray')\n",
    "\n",
    "plt.tight_layout(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Get the top dominat colors by percentage\n",
    "def get_cluser(image):\n",
    "    reshape = image.reshape((image.shape[0] * image.shape[1], 1))\n",
    "    cluster = KMeans(n_clusters=5).fit(reshape)\n",
    "    \n",
    "    return cluster, cluster.cluster_centers_\n",
    "\n",
    "\n",
    "def visualize_colors(image):\n",
    "    \n",
    "    cluster, centroids = get_cluser(image)\n",
    "    # Get the number of different clusters, create histogram, and normalize\n",
    "    labels = np.arange(0, len(np.unique(cluster.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(cluster.labels_, bins = labels)\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "\n",
    "    # Create frequency rect and iterate through each cluster's color and percentage\n",
    "    colors = sorted([(percent, color) for (percent, color) in zip(hist, centroids)])\n",
    "    \n",
    "    return [percent*100 for (percent, color) in colors]\n",
    "        \n",
    "\n",
    "\n",
    "# Get the top 5 dominant color of the original image\n",
    "original_image = visualize_colors(x_train[2])\n",
    "\n",
    "# Get the top 5 dominant colors of the feature maps, subtract from original image\n",
    "# Get mean value of the 5 differnce \n",
    "\n",
    "mean_value_diff = []\n",
    "for x in range(feature_maps.shape[-1]):\n",
    "    feature_map = visualize_colors(feature_maps[0, :, :, x])\n",
    "    mean_value_diff.append(np.mean([np.abs(a_i - b_i) for a_i, b_i in zip(original_image, feature_map)]))\n",
    "    \n",
    "# values of sorted top feature maps\n",
    "top_similair_features_values= sorted(mean_value_diff)\n",
    "\n",
    "# index of sorted top feature maps with similiar value\n",
    "top_similair_features_index = sorted(range(len(mean_value_diff)), key=lambda k: mean_value_diff[k])\n",
    "\n",
    "\n",
    "# Plot top similiar features with original image\n",
    "fig, axs = plt.subplots(nrows,ncols, \n",
    "                        figsize=(20, 20), \n",
    "                        facecolor='w', \n",
    "                        edgecolor='k',\n",
    "                       )\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(feature_maps.shape[-1]):\n",
    "\n",
    "    axs[i].imshow(feature_maps[0, :, :, top_similair_features_index[i]], cmap='gray')\n",
    "    axs[i].text(0.5,-0.1, top_similair_features_values[i], size=12, ha=\"center\", \n",
    "             transform=axs[i].transAxes)\n",
    "plt.tight_layout(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Archived </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check difference between methods\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Conv2D(4, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape,\n",
    "                 kernel_initializer='he_normal',))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model_1.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= model_1.fit(x_train_reshape, y_train,\n",
    "          epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_reshape, y_test)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following to get the parameters of the weights\n",
    "model_1.summary()\n",
    "model_1.layers[0].get_weights()\n",
    "#model_1.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model_1.layers[0].get_weights()\n",
    "column_one = [weights[0][x][0][0] for x in range(3)]\n",
    "column_two = [weights[1][x][0][0] for x in range(3)]\n",
    "column_three = [weights[2][x][0][0] for x in range(3)]\n",
    "\n",
    "print(column_one, column_two, column_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_2,b_2 = model_1.layers[2].get_weights()\n",
    "w_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((28,28,1))\n",
    "\n",
    "# Conv layer\n",
    "w,b = model_1.layers[0].get_weights()\n",
    "w = np.delete(w, [0], -1)\n",
    "b = np.delete(b, [0], 0)\n",
    "\n",
    "# FC layer\n",
    "w_2,b_2 = model_1.layers[2].get_weights()\n",
    "w_2 = w[673:,:]\n",
    "\n",
    "# Conv2D neural network\n",
    "new_c = Conv2D(3, kernel_size=(3, 3),\n",
    "               activation='relu',\n",
    "               kernel_initializer='he_normal',\n",
    "               trainable=False)\n",
    "f = Flatten()\n",
    "d = Dense(10, activation='softmax')\n",
    "\n",
    "x = new_c(inp)\n",
    "x = f(x)\n",
    "out = d(x) # -----> error!\n",
    "new_model= Model(inp, out)\n",
    "\n",
    "\n",
    "print(new_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is happening here?\n",
    "#new_model.predict(sample_mnsit)\n",
    "score = model.evaluate(x_test_reshape, y_test, verbose=0)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
