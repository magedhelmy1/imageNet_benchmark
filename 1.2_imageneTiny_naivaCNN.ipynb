{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> General Info</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO\n",
    "\n",
    "\"\"\"\n",
    "1- Implement a naive CNN on the imagenet data\n",
    "2- Implement Capsules\n",
    "\n",
    "Other info:\n",
    "Stanford prepared the Tiny ImageNet dataset for their CS231n course. \n",
    "The dataset spans 200 image classes with 500 training examples per class. \n",
    "The dataset also has 50 validation and 50 test examples per class.\n",
    "\n",
    "Tiny ImageNet Challenge is a similar challenge as ImageNet with a smaller dataset but\n",
    "less image classes. It contains 200 image classes, a training \n",
    "dataset of 100, 000 images, a validation dataset of 10, 000\n",
    "images, and a test dataset of 10, 000 images. All images are\n",
    "of size 64Ã—64.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Clear Memory\n",
    "\n",
    "from numba import cuda\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Import Data - Train<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "import datetime\n",
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(validation_split=0.9)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory= 'tiny-imagenet-200/train/', \n",
    "                                                    target_size=(64, 64), \n",
    "                                                    batch_size=256, \n",
    "                                                    class_mode='categorical', \n",
    "                                                    shuffle=True, \n",
    "                                                    seed=42,\n",
    "                                                    subset =\"training\"\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Examine Train Images </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "print(x_batch.shape)\n",
    "print(y_batch.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 5))\n",
    "\n",
    "for i in range(8):\n",
    "    sub = fig.add_subplot(2, 4, i + 1)\n",
    "    sub.imshow((x_batch[i,:,:,:]/255), interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import Data - Val<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('./tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None, names=['File', 'Class', 'X', 'Y', 'H', 'W'])\n",
    "val_data.drop(['X', 'Y', 'H', 'W'], axis=1, inplace=True)\n",
    "\n",
    "valid_datagen  = ImageDataGenerator(validation_split=0.9)\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_dataframe(dataframe=val_data, \n",
    "                                                         directory='./tiny-imagenet-200/val/images/', \n",
    "                                                         x_col='File', \n",
    "                                                         y_col='Class', \n",
    "                                                         target_size=(64, 64),\n",
    "                                                         color_mode='rgb', \n",
    "                                                         class_mode='categorical', \n",
    "                                                         batch_size=256, \n",
    "                                                         shuffle=True, \n",
    "                                                         seed=42,\n",
    "                                                        subset =\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Building the Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir)\n",
    "\n",
    "\n",
    "model= Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(64,64,3),\n",
    "                 kernel_initializer='he_normal',))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(200, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training the Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                    epochs=2, \n",
    "                    validation_data=validation_generator, \n",
    "                    #callbacks=[tensorboard_callback]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Model Evaluation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "<h1> Archive </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class TinyImageNetLoader(object):\n",
    "    \"\"\"Loader for images from the the Tiny ImageNet set for images of a specific class.\"\"\"\n",
    "    def __init__(self, mode, data_path, data_type='float32'):\n",
    "        # mode = 'train' or 'val';\n",
    "        # data_path: the relative path of tiniy-imagenet, '../tiny-imagenet-200',\n",
    "        self.data_path = data_path\n",
    "        self.data_type = data_type\n",
    "        with open(self.path('wnids.txt')) as f: # detail info of image\n",
    "            wnids = f.readlines()\n",
    "            assert len(wnids) == 200\n",
    "            wnids = [x.strip() for x in wnids]\n",
    "            self.wnids = wnids\n",
    "            self.mode = mode\n",
    "        images = {}\n",
    "        if mode == 'val': # load validation set\n",
    "            with open(self.path('val/val_annotations.txt')) as f:\n",
    "                labels = f.readlines()\n",
    "                #assert len(labels) == 10000\n",
    "                labels = [x.split('\\t')[:2] for x in labels]\n",
    "                for image, wnid in labels:\n",
    "                    #assert wnid in self.wnids\n",
    "                    #assert image.endswith('.JPEG')\n",
    "                    images.setdefault(wnid, []).append(data_path + '/val/images/' + image)\n",
    "\n",
    "                #assert len(images) == len(wnids)\n",
    "                #for wnid in images:\n",
    "                #    assert len(images[wnid]) == 50\n",
    "        if mode == 'train': # load training set\n",
    "            filenames = glob.glob(data_path + '/train/*/images/*.JPEG')\n",
    "            for filename in filenames:\n",
    "                wnid = re.search(r'n\\d+', filename)\n",
    "                #label = str(label_dict[match.group()])\n",
    "                #filenames_labels.append((filename, label))\n",
    "                images.setdefault(wnid.group(), []).append(filename)\n",
    "        self.imagefiles_wnid_dict = images\n",
    "        # print(len(self.imagefiles_wnid_dict))\n",
    "            \n",
    "\n",
    "    def path(self, *path):\n",
    "        return os.path.join(self.data_path, *path)\n",
    "\n",
    "    def load_image(self, filename):\n",
    "        path = os.path.join(filename)\n",
    "        image = Image.open(path)\n",
    "        image = np.asarray(image)\n",
    "        if image.shape != (64, 64, 3):\n",
    "            # e.g. grayscale\n",
    "            return None\n",
    "        assert image.dtype == np.uint8\n",
    "        image = image.astype(self.data_type)\n",
    "        assert image.shape == (64, 64, 3)\n",
    "        return image\n",
    "\n",
    "    def load_n_images_all_classes(self, nb):\n",
    "        # nb: number of samples per class, for validation data, max =50, for train, max=500\n",
    "        # return: X_data in [n, 64, 64, 3], Y_data in [n, 1]\n",
    "        X_data=np.ndarray([nb*200,64,64,3], dtype=self.data_type)\n",
    "        Y_data=np.zeros([nb*200,200], dtype=self.data_type)# one hot encoded\n",
    "        arr = np.arange(nb*200)\n",
    "        np.random.shuffle(arr) # shuffle images\n",
    "        \n",
    "        for label in range(200):\n",
    "            wnid = self.wnids[label]\n",
    "            files = self.imagefiles_wnid_dict[wnid]\n",
    "            for i, filename in enumerate(files):\n",
    "                if i==nb:\n",
    "                    break\n",
    "                #print(i,filename)\n",
    "                raw_image = self.load_image(filename)\n",
    "                #raw_image = raw_image.astype(np.float32)\n",
    "                #print(label*nb+i)\n",
    "                X_data[arr[label*nb+i],:,:,:] = raw_image\n",
    "                Y_data[arr[label*nb+i],label] = 1\n",
    "                #print(label)\n",
    "        return X_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:\\\\Users\\\\Maged Helmy\\\\Desktop\\\\Projects\\\\jupyterNotebooks_general\\\\4_imageNet\\\\tiny-imagenet-200\\\\\"\n",
    "\n",
    "load_data=TinyImageNetLoader(\"val\",data_path=path)\n",
    "x_data, y_data= load_data.load_n_images_all_classes(nb=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
